{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covolutional Neural Network to classify MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Load the MNIST dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Plotting images from our dataset\n",
    "num_images = 5\n",
    "\n",
    "random_indices = np.random.randint(0, len(x_train), num_images)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i, index in enumerate(random_indices):\n",
    "    plt.subplot(1, num_images, i + 1)\n",
    "    plt.imshow(x_train[index], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train[index]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the data\n",
    "\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))  # Reshape for CNN (add a channel dimension)\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "x_train = x_train.astype('float32') / 255.0  # Normalize pixel values to [0, 1]\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)  # One-hot encode labels\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 14:11:44.736720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-05 14:11:44.753982: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-05 14:11:44.754129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-05 14:11:44.755250: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-05 14:11:44.755379: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-05 14:11:44.755458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-05 14:11:44.791423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-05 14:11:44.791688: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-05 14:11:44.791781: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-09-05 14:11:44.791851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1118 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Build the Convolutional neural network model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))  # 32 filters, 3x3 kernel\n",
    "model.add(MaxPooling2D((2, 2)))  # Max pooling layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))  # 64 filters, 3x3 kernel\n",
    "model.add(MaxPooling2D((2, 2)))  # Max pooling layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))  # Fully connected layer with 128 neurons\n",
    "model.add(Dropout(0.5))  # Dropout layer for regularization\n",
    "model.add(Dense(10, activation='softmax'))  # Output layer with 10 units (for 10 classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Compile the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-05 14:11:45.574566: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-09-05 14:11:45.682866: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-05 14:11:45.683377: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-05 14:11:45.683398: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-09-05 14:11:45.684034: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-09-05 14:11:45.684079: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:317] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-09-05 14:11:45.774962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-09-05 14:11:45.816290: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fc5d6e10310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-05 14:11:45.816307: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2023-09-05 14:11:45.819236: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-05 14:11:45.833696: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:530] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.8\n",
      "  /usr/local/cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2023-09-05 14:11:45.833870: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:45.834074: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:45.834093: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "\t [[{{node StatefulPartitionedCall_6}}]]\n",
      "2023-09-05 14:11:45.848007: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:45.848272: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:45.863461: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:45.863728: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:45.877760: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:45.877968: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:46.048238: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:46.048486: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:46.062382: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:46.062629: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:46.131680: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:46.132030: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:46.147611: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-05 14:11:46.147871: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_6' defined at (most recent call last):\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_11159/3758108699.py\", line 5, in <module>\n      model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_6'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_6}}]] [Op:__inference_train_function_1210]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m\n\u001b[1;32m      4\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, batch_size\u001b[39m=\u001b[39;49mbatch_size, epochs\u001b[39m=\u001b[39;49mepochs, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_6' defined at (most recent call last):\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_11159/3758108699.py\", line 5, in <module>\n      model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/shash/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_6'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_6}}]] [Op:__inference_train_function_1210]"
     ]
    }
   ],
   "source": [
    "# Step 5: Train the model\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the model\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
